{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:12.994519Z",
     "iopub.status.busy": "2024-04-24T13:04:12.993736Z",
     "iopub.status.idle": "2024-04-24T13:04:20.53177Z",
     "shell.execute_reply": "2024-04-24T13:04:20.530625Z",
     "shell.execute_reply.started": "2024-04-24T13:04:12.994425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#IMPORT THE LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM,BatchNormalization , GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import tensorflow as tf \n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:32.289159Z",
     "iopub.status.busy": "2024-04-24T13:04:32.2883Z",
     "iopub.status.idle": "2024-04-24T13:04:32.293832Z",
     "shell.execute_reply": "2024-04-24T13:04:32.292846Z",
     "shell.execute_reply.started": "2024-04-24T13:04:32.289116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Tess = \"tess toronto emotional speech set data/TESS Toronto emotional speech set data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:33.169029Z",
     "iopub.status.busy": "2024-04-24T13:04:33.168759Z",
     "iopub.status.idle": "2024-04-24T13:04:34.0387Z",
     "shell.execute_reply": "2024-04-24T13:04:34.037622Z",
     "shell.execute_reply.started": "2024-04-24T13:04:33.169003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for file in directories:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')[2]\n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "        file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "# dataframe for emotion of files\n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files.\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Tess_df.head()\n",
    "print(Tess_df.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:34.203531Z",
     "iopub.status.busy": "2024-04-24T13:04:34.203179Z",
     "iopub.status.idle": "2024-04-24T13:04:34.280443Z",
     "shell.execute_reply": "2024-04-24T13:04:34.279508Z",
     "shell.execute_reply.started": "2024-04-24T13:04:34.203499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# creating Dataframe using all the 4 dataframes we created so far.\n",
    "data_path = Tess_df\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:34.282266Z",
     "iopub.status.busy": "2024-04-24T13:04:34.281887Z",
     "iopub.status.idle": "2024-04-24T13:04:34.290951Z",
     "shell.execute_reply": "2024-04-24T13:04:34.28994Z",
     "shell.execute_reply.started": "2024-04-24T13:04:34.282228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(data_path.Emotions.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*                           Data Visualisation and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:34.292601Z",
     "iopub.status.busy": "2024-04-24T13:04:34.292193Z",
     "iopub.status.idle": "2024-04-24T13:04:34.563253Z",
     "shell.execute_reply": "2024-04-24T13:04:34.562305Z",
     "shell.execute_reply.started": "2024-04-24T13:04:34.292571Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.title('Count of Emotions', size=16)\n",
    "sns.countplot(data_path.Emotions)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Emotions', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:34.568724Z",
     "iopub.status.busy": "2024-04-24T13:04:34.568354Z",
     "iopub.status.idle": "2024-04-24T13:04:35.904484Z",
     "shell.execute_reply": "2024-04-24T13:04:35.903299Z",
     "shell.execute_reply.started": "2024-04-24T13:04:34.568695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data,sr = librosa.load(file_path[0])\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:35.906576Z",
     "iopub.status.busy": "2024-04-24T13:04:35.906079Z",
     "iopub.status.idle": "2024-04-24T13:04:35.922266Z",
     "shell.execute_reply": "2024-04-24T13:04:35.921184Z",
     "shell.execute_reply.started": "2024-04-24T13:04:35.906516Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:36.327484Z",
     "iopub.status.busy": "2024-04-24T13:04:36.327125Z",
     "iopub.status.idle": "2024-04-24T13:04:36.592756Z",
     "shell.execute_reply": "2024-04-24T13:04:36.591822Z",
     "shell.execute_reply.started": "2024-04-24T13:04:36.327454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)\n",
    "\n",
    "\n",
    "# MFCC\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(3,1,1)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "plt.ylabel('MFCC')\n",
    "plt.colorbar()\n",
    "\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:36.5963Z",
     "iopub.status.busy": "2024-04-24T13:04:36.595999Z",
     "iopub.status.idle": "2024-04-24T13:04:36.604163Z",
     "shell.execute_reply": "2024-04-24T13:04:36.60315Z",
     "shell.execute_reply.started": "2024-04-24T13:04:36.596271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NOISE\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "    \n",
    "# PITCH\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:36.606001Z",
     "iopub.status.busy": "2024-04-24T13:04:36.605411Z",
     "iopub.status.idle": "2024-04-24T13:04:37.042284Z",
     "shell.execute_reply": "2024-04-24T13:04:37.041339Z",
     "shell.execute_reply.started": "2024-04-24T13:04:36.60596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NORMAL AUDIO\n",
    "\n",
    "\n",
    "import librosa.display\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=data, sr=sr)\n",
    "ipd.Audio(data,rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:37.043597Z",
     "iopub.status.busy": "2024-04-24T13:04:37.043287Z",
     "iopub.status.idle": "2024-04-24T13:04:37.421452Z",
     "shell.execute_reply": "2024-04-24T13:04:37.420454Z",
     "shell.execute_reply.started": "2024-04-24T13:04:37.043568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# AUDIO WITH NOISE\n",
    "x = noise(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:37.423271Z",
     "iopub.status.busy": "2024-04-24T13:04:37.422852Z",
     "iopub.status.idle": "2024-04-24T13:04:38.277428Z",
     "shell.execute_reply": "2024-04-24T13:04:38.276481Z",
     "shell.execute_reply.started": "2024-04-24T13:04:37.423229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# STRETCHED AUDIO\n",
    "x = stretch(data)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:38.279224Z",
     "iopub.status.busy": "2024-04-24T13:04:38.278818Z",
     "iopub.status.idle": "2024-04-24T13:04:38.631132Z",
     "shell.execute_reply": "2024-04-24T13:04:38.630199Z",
     "shell.execute_reply.started": "2024-04-24T13:04:38.279182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SHIFTED AUDIO\n",
    "x = shift(data)\n",
    "plt.figure(figsize=(12,5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:38.63324Z",
     "iopub.status.busy": "2024-04-24T13:04:38.632576Z",
     "iopub.status.idle": "2024-04-24T13:04:39.10176Z",
     "shell.execute_reply": "2024-04-24T13:04:39.100777Z",
     "shell.execute_reply.started": "2024-04-24T13:04:38.633198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# AUDIO WITH PITCH\n",
    "x = pitch(data, sr)\n",
    "plt.figure(figsize=(12, 5))\n",
    "librosa.display.waveshow(y=x, sr=sr)\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:39.10361Z",
     "iopub.status.busy": "2024-04-24T13:04:39.103187Z",
     "iopub.status.idle": "2024-04-24T13:04:39.118271Z",
     "shell.execute_reply": "2024-04-24T13:04:39.117024Z",
     "shell.execute_reply.started": "2024-04-24T13:04:39.103569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def calculate_chroma(data, sr, hop_length=512, flatten=True):\n",
    "    chroma = librosa.feature.chroma_stft(y=data, sr=sr, hop_length=hop_length)\n",
    "    return np.squeeze(chroma.T) if not flatten else np.ravel(chroma.T)\n",
    "\n",
    "def extract_features(data,sr=22050,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      calculate_chroma(data, sr, hop_length)\n",
    "                     ))\n",
    "    return result\n",
    "\n",
    "def get_features(path,duration=2.5, offset=0.6):\n",
    "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
    "    aud=extract_features(data)\n",
    "    audio=np.array(aud)\n",
    "    \n",
    "    noised_audio=noise(data)\n",
    "    aud2=extract_features(noised_audio)\n",
    "    audio=np.vstack((audio,aud2))\n",
    "    \n",
    "    pitched_audio=pitch(data,sr)\n",
    "    aud3=extract_features(pitched_audio)\n",
    "    audio=np.vstack((audio,aud3))\n",
    "    \n",
    "    pitched_audio1=pitch(data,sr)\n",
    "    pitched_noised_audio=noise(pitched_audio1)\n",
    "    aud4=extract_features(pitched_noised_audio)\n",
    "    audio=np.vstack((audio,aud4))\n",
    "    \n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:39.119969Z",
     "iopub.status.busy": "2024-04-24T13:04:39.119669Z",
     "iopub.status.idle": "2024-04-24T13:04:39.132773Z",
     "shell.execute_reply": "2024-04-24T13:04:39.131788Z",
     "shell.execute_reply.started": "2024-04-24T13:04:39.11994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noraml way to get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T13:04:39.134428Z",
     "iopub.status.busy": "2024-04-24T13:04:39.134056Z",
     "iopub.status.idle": "2024-04-24T14:38:54.437609Z",
     "shell.execute_reply": "2024-04-24T14:38:54.430505Z",
     "shell.execute_reply.started": "2024-04-24T13:04:39.134393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "from tqdm import tqdm\n",
    "start = timeit.default_timer()\n",
    "X,Y=[],[]\n",
    "for path,emotion,index in tqdm (zip(data_path.Path,data_path.Emotions,range(data_path.Path.shape[0]))):\n",
    "    features=get_features(path)\n",
    "    if index%500==0:\n",
    "        print(f'{index} audio has been processed')\n",
    "    for i in features:\n",
    "        X.append(i)\n",
    "        Y.append(emotion)\n",
    "print('Done')\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster way to get features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  The .extend() method increases the length of the list by the number of elements that are provided to the method, so if you want to add multiple elements to the list, you can use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T14:38:54.453047Z",
     "iopub.status.busy": "2024-04-24T14:38:54.452359Z",
     "iopub.status.idle": "2024-04-24T14:38:54.478865Z",
     "shell.execute_reply": "2024-04-24T14:38:54.476571Z",
     "shell.execute_reply.started": "2024-04-24T14:38:54.453Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(X), len(Y), data_path.Path.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T14:38:54.481853Z",
     "iopub.status.busy": "2024-04-24T14:38:54.481032Z",
     "iopub.status.idle": "2024-04-24T14:42:38.057564Z",
     "shell.execute_reply": "2024-04-24T14:42:38.05653Z",
     "shell.execute_reply.started": "2024-04-24T14:38:54.481799Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Emotions = pd.DataFrame(X)\n",
    "Emotions['Emotions'] = Y\n",
    "Emotions.to_csv('emotion.csv', index=False)\n",
    "Emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-24T14:42:38.059141Z",
     "iopub.status.busy": "2024-04-24T14:42:38.05883Z",
     "iopub.status.idle": "2024-04-24T14:43:08.049642Z",
     "shell.execute_reply": "2024-04-24T14:43:08.048588Z",
     "shell.execute_reply.started": "2024-04-24T14:42:38.059111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Emotions = pd.read_csv('./emotion.csv')\n",
    "Emotions.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 107620,
     "sourceId": 256618,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 316368,
     "sourceId": 639622,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 325566,
     "sourceId": 653195,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 338555,
     "sourceId": 671851,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3468263,
     "sourceId": 6060815,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30380,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
